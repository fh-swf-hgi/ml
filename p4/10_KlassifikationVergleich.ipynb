{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Machine Learning\n",
    "### Sommersemester 2021\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich von Klassifikationsverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verwenden einen zufällig generierten Datensatz um die *Logistische Regression*, *Entscheidungsbäume* und *Random Forrests* miteinander zu vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_classes = 10 #change this\n",
    "n_data = 400 # change this\n",
    "n_dimensions = 2 # kept to two dimensions for easy visualization\n",
    "\n",
    "# generating ten-class dataset\n",
    "X, y = make_blobs(n_samples=n_data, centers=n_classes, n_features=n_dimensions)\n",
    "\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Trainieren Sie 3 verschiedene Modell auf den generierten Datensatz:\n",
    "- Logistische Regression (`LogisticRegression`)\n",
    "- Entscheidungsbaum (`DecisionTreeClassifier`)\n",
    "- Random Forrest (`RandomForestClassifier`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "472536ef26f01fc708cfc4e2ae7f477f",
     "grade": false,
     "grade_id": "cell-e1c82e012b55052a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6db1e82893b659a17684e4b1c761048",
     "grade": true,
     "grade_id": "cell-378f76ab471ccb61",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "#----------\n",
    "# Model building\n",
    "\n",
    "assert type(logreg) == LogisticRegression\n",
    "assert type(tree) == DecisionTreeClassifier\n",
    "assert type(forest) == RandomForestClassifier\n",
    "#----------\n",
    "\n",
    "#----------\n",
    "# Model training\n",
    "\n",
    "assert (logreg.intercept_).any(), 'Make sure to fit the data to logreg model'\n",
    "assert (tree.classes_).any() , 'Make sure to fit the data to tree model'\n",
    "assert (forest.classes_).any() , 'Make sure to fit the data to forest model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "models = [logreg, tree, forest]\n",
    "names = ['Logistische Regression', 'Entscheidungsbaum', 'Random Forest']\n",
    "figure = plt.figure(figsize=(20, 6))\n",
    "\n",
    "for i, (name, model) in enumerate(zip(names, models)):\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    score = model.score(X_train, y_train)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdBu)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu)\n",
    "    plt.xlabel(\"X0\", fontsize=14)\n",
    "    plt.ylabel(\"X1\", fontsize=14)\n",
    "    plt.title(name+': %d%%' %(score*100))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse für den Entscheidungsbaum sowie den Random Forrest sind sehr hoch, auf den Plots sieht es aber so aus, als würden die Modelle *overfitten*. Wir wollen das anhand der Testdaten überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model) in zip(names, models):\n",
    "    score_test = model.score(X_test, y_test)*100\n",
    "    score_train = model.score(X_train, y_train)*100\n",
    "    print('%s: training accuracy %d%%, test accuracy %d%%' % (name, score_train, score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tatsächlich liegt bei den Modellen Overfitting vor. Um diese zu umgehen, wollen wir die Tiefe der Bäume beschränken (auch *pruning* genannt). Dies wird dazu führen, dass die Modelle besser verallgemeinern.\n",
    "Eine Variante, das sogenannte *Cost-Complexity Pruning*, lässt sich über den Parameter `ccp_alpha` einstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 0.02, 0.001) # testing alpha range\n",
    "score = []\n",
    "# iterating over different alpha values\n",
    "for alpha in alphas:\n",
    "    tree = DecisionTreeClassifier(ccp_alpha =alpha).fit(X_train,y_train)\n",
    "    score.append([tree.score(X_test, y_test), tree.score(X_train, y_train)])\n",
    "score = np.array(score)*100\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Entscheidungsbaum: Accuracy vs. alpha\")\n",
    "ax.plot(alphas, score[:,0],'-o', label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.plot(alphas, score[:,1],'-o', label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Die Vorshersagegenauigkeit ist mit %d%% am besten für alpha=%.3f' \n",
    "      % (np.max(score[:,0]), alphas[np.argmax(score[:,0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das gleiche Vorgehen könne wir für Random Forrests anwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 0.02, 0.001)\n",
    "score = []\n",
    "for alpha in alphas:\n",
    "    tree = RandomForestClassifier(n_estimators=100, ccp_alpha =alpha).fit(X_train,y_train)\n",
    "    score.append([tree.score(X_test, y_test), tree.score(X_train, y_train)])\n",
    "score = np.array(score)*100\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha\")\n",
    "ax.plot(alphas, score[:,0],'-o', label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.plot(alphas, score[:,1],'-o', label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Die Vorshersagegenauigkeit ist mit %d%% am besten für alpha=%.3f' \n",
    "      % (np.max(score[:,0]), alphas[np.argmax(score[:,0])]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
